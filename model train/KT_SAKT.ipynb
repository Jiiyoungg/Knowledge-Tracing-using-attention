{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxgUH5dW6i1J"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import pickle\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.utils.rnn as rnn_utils\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDB1RI_p6re5",
        "outputId": "ceac56bd-351c-497f-b3f2-7245bf6a5caa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdCRmTSR6i1N"
      },
      "outputs": [],
      "source": [
        "MAX_SEQ = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocwSVnQA6i1N",
        "outputId": "f2bcaf8f-245b-4716-8c9d-641b9f8c5f07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<timed exec>:1: DtypeWarning: Columns (0,11,16,18,20,22,24) have mixed types. Specify dtype option on import or set low_memory=False.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 48.8 s, sys: 5.59 s, total: 54.4 s\n",
            "Wall time: 1min 8s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "df = pd.read_csv('/content/drive/MyDrive/.csv')\\\n",
        "            .dropna(subset=[\"memb_no\", \"chg_dt\",\"chapter_nm\"]).sort_values(by=[\"chg_dt\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X68IUL816i1O"
      },
      "source": [
        "## Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dl0clWFl6i1Q"
      },
      "outputs": [],
      "source": [
        "#df = train_df.copy()\n",
        "df[\"memb_no\"] = df[\"memb_no\"].astype(\"str\")\n",
        "df[\"unit\"] = df[\"chapter_nm4\"].astype(\"str\")\n",
        "df[\"correct\"] = df[\"ox_yn\"].apply(lambda x: 1 if x == \"O\" else 0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2LGQvAM6i1R",
        "outputId": "d26ea93e-e2d5-45e5-ef47-aeaaa9336149"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "922"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "\n",
        "df[\"unit\"] = df[\"unit\"].apply(lambda x: x.split(\".\")[-1].strip()).apply(lambda x: re.sub('\\(\\s*\\d+\\s*\\)', '', x).strip())\n",
        "df.unit.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfTPQxsZ6i1R"
      },
      "outputs": [],
      "source": [
        "u_list = np.unique(df[\"memb_no\"].values)\n",
        "q_list = df.sort_values(by=[\"subject_cd\", \"chapter_cd\"])['unit'].unique()\n",
        "\n",
        "u2idx = {u: idx for idx, u in enumerate(u_list)}\n",
        "q2idx = {q: idx for idx, q in enumerate(q_list)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFootmPS6i1S"
      },
      "outputs": [],
      "source": [
        "df['content_id'] = df['unit'].replace(q2idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grP7Wgd_6i1S"
      },
      "outputs": [],
      "source": [
        "group = df[['memb_no', 'content_id', 'correct']].groupby('memb_no').apply(lambda r: (\n",
        "            r['content_id'].values,\n",
        "            r['correct'].values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iwS-CWP6i1T"
      },
      "outputs": [],
      "source": [
        "SEED = 0\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDwD-IOH6i1T"
      },
      "outputs": [],
      "source": [
        "class SAKTDataset(Dataset):\n",
        "    def __init__(self, group, n_skill, max_seq=100):\n",
        "        super(SAKTDataset, self).__init__()\n",
        "        self.max_seq = max_seq\n",
        "        self.n_skill = n_skill\n",
        "        self.samples = group\n",
        "\n",
        "#         self.user_ids = [x for x in group.index]\n",
        "        self.user_ids = []\n",
        "        for user_id in group.index:\n",
        "            q, qa = group[user_id]\n",
        "            if len(q) < 10:\n",
        "                continue\n",
        "            self.user_ids.append(user_id)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.user_ids)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        user_id = self.user_ids[index]\n",
        "        q_, qa_ = self.samples[user_id]\n",
        "        seq_len = len(q_)\n",
        "\n",
        "        q = np.zeros(self.max_seq, dtype=int)\n",
        "        qa = np.zeros(self.max_seq, dtype=int)\n",
        "        if seq_len >= self.max_seq:\n",
        "            q[:] = q_[-self.max_seq:]\n",
        "            qa[:] = qa_[-self.max_seq:]\n",
        "        else:\n",
        "            q[-seq_len:] = q_\n",
        "            qa[-seq_len:] = qa_\n",
        "\n",
        "        target_id = q[1:]\n",
        "        label = qa[1:]\n",
        "\n",
        "        x = np.zeros(self.max_seq-1, dtype=int)\n",
        "        x = q[:-1].copy()\n",
        "        x += (qa[:-1] == 1) * self.n_skill\n",
        "\n",
        "        return x, target_id, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSnUk7z76i1T",
        "outputId": "890a9afc-b9f9-4f9d-f0df-5b924ef18da3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "train, val = train_test_split(group, test_size=0.2)\n",
        "\n",
        "train_dataset = SAKTDataset(train, n_skill)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=2048, shuffle=True, num_workers=8)\n",
        "del train\n",
        "\n",
        "val_dataset = SAKTDataset(val, n_skill)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=2048, shuffle=True, num_workers=8)\n",
        "del val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBH5Zddg6i1U"
      },
      "outputs": [],
      "source": [
        "class FFN(nn.Module):\n",
        "    def __init__(self, state_size=200):\n",
        "        super(FFN, self).__init__()\n",
        "        self.state_size = state_size\n",
        "\n",
        "        self.lr1 = nn.Linear(state_size, state_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.lr2 = nn.Linear(state_size, state_size)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lr1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.lr2(x)\n",
        "        return self.dropout(x)\n",
        "\n",
        "def future_mask(seq_length):\n",
        "    future_mask = np.triu(np.ones((seq_length, seq_length)), k=1).astype('bool')\n",
        "    return torch.from_numpy(future_mask)\n",
        "\n",
        "\n",
        "class SAKTModel(nn.Module):\n",
        "    def __init__(self, n_skill, max_seq=100, embed_dim=128):\n",
        "        super(SAKTModel, self).__init__()\n",
        "        self.n_skill = n_skill\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(2*n_skill+1, embed_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_seq-1, embed_dim)\n",
        "        self.e_embedding = nn.Embedding(n_skill+1, embed_dim)\n",
        "\n",
        "        self.multi_att = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=8, dropout=0.2)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.layer_normal = nn.LayerNorm(embed_dim)\n",
        "\n",
        "        self.ffn = FFN(embed_dim)\n",
        "        self.pred = nn.Linear(embed_dim, 1)\n",
        "\n",
        "    def forward(self, x, question_ids):\n",
        "        device = x.device\n",
        "        x = self.embedding(x)\n",
        "        pos_id = torch.arange(x.size(1)).unsqueeze(0).to(device)\n",
        "\n",
        "        pos_x = self.pos_embedding(pos_id)\n",
        "        x = x + pos_x\n",
        "\n",
        "        e = self.e_embedding(question_ids)\n",
        "\n",
        "        x = x.permute(1, 0, 2) # x: [bs, s_len, embed] => [s_len, bs, embed]\n",
        "        e = e.permute(1, 0, 2)\n",
        "        att_mask = future_mask(x.size(0)).to(device)\n",
        "        att_output, att_weight = self.multi_att(e, x, x, attn_mask=att_mask)\n",
        "        att_output = self.layer_normal(att_output + e)\n",
        "        att_output = att_output.permute(1, 0, 2) # att_output: [s_len, bs, embed] => [bs, s_len, embed]\n",
        "\n",
        "        x = self.ffn(att_output)\n",
        "        x = self.layer_normal(x + att_output)\n",
        "        x = self.pred(x)\n",
        "\n",
        "        return x.squeeze(-1), att_weight\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spxLIAlG6i1U",
        "outputId": "4f42a48b-dd68-4835-f74c-3bf567c230f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BCEWithLogitsLoss()"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# device = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "model = SAKTModel(n_skill, embed_dim=128)\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.99, weight_decay=0.005)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model.to(device)\n",
        "criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2WNXZ5m6i1U"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, train_iterator, optim, criterion, device=\"cpu\"):\n",
        "    model.train()\n",
        "\n",
        "    train_loss = []\n",
        "    num_corrects = 0\n",
        "    num_total = 0\n",
        "    labels = []\n",
        "    outs = []\n",
        "\n",
        "    tbar = tqdm(train_iterator)\n",
        "    for item in tbar:\n",
        "        x = item[0].to(device).long()\n",
        "        target_id = item[1].to(device).long()\n",
        "        label = item[2].to(device).float()\n",
        "        target_mask = (target_id != 0)\n",
        "\n",
        "        optim.zero_grad()\n",
        "        output, atten_weight = model(x, target_id)\n",
        "\n",
        "        output = torch.masked_select(output, target_mask)\n",
        "        label = torch.masked_select(label, target_mask)\n",
        "\n",
        "        loss = criterion(output, label)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        train_loss.append(loss.item())\n",
        "        pred = (torch.sigmoid(output) >= 0.5).long()\n",
        "\n",
        "        num_corrects += (pred == label).sum().item()\n",
        "        num_total += len(label)\n",
        "\n",
        "        labels.extend(label.view(-1).data.cpu().numpy())\n",
        "        outs.extend(output.view(-1).data.cpu().numpy())\n",
        "\n",
        "        tbar.set_description('loss - {:.4f}'.format(loss))\n",
        "\n",
        "    acc = num_corrects / num_total\n",
        "    auc = roc_auc_score(labels, outs)\n",
        "    loss = np.average(train_loss)\n",
        "\n",
        "    return loss, acc, auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92bpsgB26i1U"
      },
      "outputs": [],
      "source": [
        "def val_epoch(model, val_iterator, criterion, device=\"cpu\"):\n",
        "    model.eval()\n",
        "\n",
        "    train_loss = []\n",
        "    num_corrects = 0\n",
        "    num_total = 0\n",
        "    labels = []\n",
        "    outs = []\n",
        "\n",
        "    tbar = tqdm(val_iterator)\n",
        "    for item in tbar:\n",
        "        x = item[0].to(device).long()\n",
        "        target_id = item[1].to(device).long()\n",
        "        label = item[2].to(device).float()\n",
        "        target_mask = (target_id != 0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, atten_weight = model(x, target_id)\n",
        "\n",
        "        output = torch.masked_select(output, target_mask)\n",
        "        label = torch.masked_select(label, target_mask)\n",
        "\n",
        "        loss = criterion(output, label)\n",
        "        train_loss.append(loss.item())\n",
        "\n",
        "        pred = (torch.sigmoid(output) >= 0.5).long()\n",
        "\n",
        "        num_corrects += (pred == label).sum().item()\n",
        "        num_total += len(label)\n",
        "\n",
        "        labels.extend(label.view(-1).data.cpu().numpy())\n",
        "        outs.extend(output.view(-1).data.cpu().numpy())\n",
        "\n",
        "        tbar.set_description('loss - {:.4f}'.format(loss))\n",
        "\n",
        "    acc = num_corrects / num_total\n",
        "    auc = roc_auc_score(labels, outs)\n",
        "    loss = np.average(train_loss)\n",
        "\n",
        "    return loss, acc, auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32u9dk1D6i1U",
        "outputId": "d6e74602-dd64-49f9-8d93-a6e4fea7cd03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss - 0.5595: 100%|██████████| 12/12 [00:08<00:00,  1.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 0 train_loss - 0.61 acc - 0.703 auc - 0.504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.5506: 100%|██████████| 3/3 [00:01<00:00,  2.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 0 val_loss - 0.56 acc - 0.752 auc - 0.580\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.5384: 100%|██████████| 12/12 [00:03<00:00,  3.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 1 train_loss - 0.55 acc - 0.752 auc - 0.593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.5392: 100%|██████████| 3/3 [00:01<00:00,  2.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 1 val_loss - 0.54 acc - 0.757 auc - 0.614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.5600: 100%|██████████| 12/12 [00:03<00:00,  3.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 2 train_loss - 0.54 acc - 0.753 auc - 0.623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.5338: 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 2 val_loss - 0.53 acc - 0.757 auc - 0.637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.5406: 100%|██████████| 12/12 [00:03<00:00,  3.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 3 train_loss - 0.54 acc - 0.754 auc - 0.642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.5310: 100%|██████████| 3/3 [00:01<00:00,  2.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 3 val_loss - 0.53 acc - 0.757 auc - 0.653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.5325: 100%|██████████| 12/12 [00:03<00:00,  3.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 4 train_loss - 0.53 acc - 0.755 auc - 0.660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.5218: 100%|██████████| 3/3 [00:01<00:00,  1.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 4 val_loss - 0.52 acc - 0.759 auc - 0.669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.5281: 100%|██████████| 12/12 [00:04<00:00,  2.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 5 train_loss - 0.52 acc - 0.758 auc - 0.678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.5149: 100%|██████████| 3/3 [00:01<00:00,  2.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 5 val_loss - 0.51 acc - 0.764 auc - 0.685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.5095: 100%|██████████| 12/12 [00:03<00:00,  3.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 6 train_loss - 0.51 acc - 0.764 auc - 0.696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.5069: 100%|██████████| 3/3 [00:01<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 6 val_loss - 0.51 acc - 0.769 auc - 0.702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4991: 100%|██████████| 12/12 [00:04<00:00,  2.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 7 train_loss - 0.50 acc - 0.769 auc - 0.711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.5018: 100%|██████████| 3/3 [00:01<00:00,  2.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 7 val_loss - 0.50 acc - 0.773 auc - 0.714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.5126: 100%|██████████| 12/12 [00:03<00:00,  3.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 8 train_loss - 0.50 acc - 0.773 auc - 0.723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4955: 100%|██████████| 3/3 [00:01<00:00,  2.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 8 val_loss - 0.49 acc - 0.776 auc - 0.722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4913: 100%|██████████| 12/12 [00:04<00:00,  2.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 9 train_loss - 0.49 acc - 0.776 auc - 0.731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4841: 100%|██████████| 3/3 [00:01<00:00,  2.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 9 val_loss - 0.49 acc - 0.778 auc - 0.727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4861: 100%|██████████| 12/12 [00:03<00:00,  3.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 10 train_loss - 0.49 acc - 0.778 auc - 0.737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4863: 100%|██████████| 3/3 [00:01<00:00,  2.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 10 val_loss - 0.49 acc - 0.780 auc - 0.732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4715: 100%|██████████| 12/12 [00:03<00:00,  3.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 11 train_loss - 0.48 acc - 0.780 auc - 0.742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4873: 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 11 val_loss - 0.48 acc - 0.781 auc - 0.736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4716: 100%|██████████| 12/12 [00:03<00:00,  3.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 12 train_loss - 0.48 acc - 0.782 auc - 0.746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4806: 100%|██████████| 3/3 [00:01<00:00,  2.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 12 val_loss - 0.48 acc - 0.781 auc - 0.739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4819: 100%|██████████| 12/12 [00:03<00:00,  3.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 13 train_loss - 0.48 acc - 0.783 auc - 0.749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4777: 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 13 val_loss - 0.48 acc - 0.783 auc - 0.741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4897: 100%|██████████| 12/12 [00:04<00:00,  2.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 14 train_loss - 0.48 acc - 0.784 auc - 0.752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4770: 100%|██████████| 3/3 [00:01<00:00,  2.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 14 val_loss - 0.48 acc - 0.783 auc - 0.742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4838: 100%|██████████| 12/12 [00:03<00:00,  3.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 15 train_loss - 0.48 acc - 0.784 auc - 0.754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4824: 100%|██████████| 3/3 [00:01<00:00,  1.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 15 val_loss - 0.48 acc - 0.783 auc - 0.743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4695: 100%|██████████| 12/12 [00:04<00:00,  2.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 16 train_loss - 0.47 acc - 0.785 auc - 0.756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4771: 100%|██████████| 3/3 [00:01<00:00,  2.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 16 val_loss - 0.48 acc - 0.784 auc - 0.745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4691: 100%|██████████| 12/12 [00:03<00:00,  3.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 17 train_loss - 0.47 acc - 0.786 auc - 0.758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4791: 100%|██████████| 3/3 [00:01<00:00,  2.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 17 val_loss - 0.48 acc - 0.784 auc - 0.746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4832: 100%|██████████| 12/12 [00:04<00:00,  2.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 18 train_loss - 0.47 acc - 0.787 auc - 0.760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4766: 100%|██████████| 3/3 [00:01<00:00,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 18 val_loss - 0.48 acc - 0.784 auc - 0.747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4604: 100%|██████████| 12/12 [00:03<00:00,  3.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 19 train_loss - 0.47 acc - 0.787 auc - 0.761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4770: 100%|██████████| 3/3 [00:01<00:00,  2.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 19 val_loss - 0.48 acc - 0.784 auc - 0.747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4777: 100%|██████████| 12/12 [00:04<00:00,  2.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 20 train_loss - 0.47 acc - 0.788 auc - 0.763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4805: 100%|██████████| 3/3 [00:01<00:00,  2.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 20 val_loss - 0.48 acc - 0.784 auc - 0.748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4695: 100%|██████████| 12/12 [00:03<00:00,  3.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 21 train_loss - 0.47 acc - 0.788 auc - 0.764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4826: 100%|██████████| 3/3 [00:01<00:00,  2.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 21 val_loss - 0.48 acc - 0.785 auc - 0.748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4623: 100%|██████████| 12/12 [00:03<00:00,  3.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 22 train_loss - 0.47 acc - 0.789 auc - 0.765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4815: 100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 22 val_loss - 0.48 acc - 0.785 auc - 0.749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4712: 100%|██████████| 12/12 [00:03<00:00,  3.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 23 train_loss - 0.47 acc - 0.789 auc - 0.766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4792: 100%|██████████| 3/3 [00:01<00:00,  2.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 23 val_loss - 0.48 acc - 0.785 auc - 0.749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4756: 100%|██████████| 12/12 [00:03<00:00,  3.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 24 train_loss - 0.47 acc - 0.790 auc - 0.767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4729: 100%|██████████| 3/3 [00:01<00:00,  1.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 24 val_loss - 0.48 acc - 0.785 auc - 0.749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4681: 100%|██████████| 12/12 [00:04<00:00,  2.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 25 train_loss - 0.47 acc - 0.790 auc - 0.768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4745: 100%|██████████| 3/3 [00:01<00:00,  2.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 25 val_loss - 0.48 acc - 0.785 auc - 0.750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4575: 100%|██████████| 12/12 [00:03<00:00,  3.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 26 train_loss - 0.46 acc - 0.790 auc - 0.769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4786: 100%|██████████| 3/3 [00:01<00:00,  1.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 26 val_loss - 0.48 acc - 0.785 auc - 0.750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4781: 100%|██████████| 12/12 [00:04<00:00,  2.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 27 train_loss - 0.47 acc - 0.791 auc - 0.770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4727: 100%|██████████| 3/3 [00:01<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 27 val_loss - 0.48 acc - 0.785 auc - 0.750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4572: 100%|██████████| 12/12 [00:03<00:00,  3.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 28 train_loss - 0.46 acc - 0.791 auc - 0.771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4818: 100%|██████████| 3/3 [00:01<00:00,  2.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 28 val_loss - 0.48 acc - 0.785 auc - 0.750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4607: 100%|██████████| 12/12 [00:04<00:00,  2.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 29 train_loss - 0.46 acc - 0.791 auc - 0.772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4704: 100%|██████████| 3/3 [00:01<00:00,  2.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 29 val_loss - 0.48 acc - 0.785 auc - 0.750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/12 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4484: 100%|██████████| 12/12 [00:03<00:00,  3.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 30 train_loss - 0.46 acc - 0.792 auc - 0.773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4790: 100%|██████████| 3/3 [00:01<00:00,  2.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 30 val_loss - 0.48 acc - 0.785 auc - 0.750\n",
            "early stop epoch  30\n"
          ]
        }
      ],
      "source": [
        "epochs = 50\n",
        "\n",
        "over_fit = 0\n",
        "last_auc = 0\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_acc, train_auc = train_epoch(model, train_dataloader, optimizer, criterion, device)\n",
        "    print(\"epoch - {} train_loss - {:.2f} acc - {:.3f} auc - {:.3f}\".format(epoch, train_loss, train_acc, train_auc))\n",
        "\n",
        "    val_loss, avl_acc, val_auc = val_epoch(model, val_dataloader, criterion, device)\n",
        "    print(\"epoch - {} val_loss - {:.2f} acc - {:.3f} auc - {:.3f}\".format(epoch, val_loss, avl_acc, val_auc))\n",
        "\n",
        "    if val_auc > last_auc:\n",
        "        last_auc = val_auc\n",
        "        over_fit = 0\n",
        "    else:\n",
        "        over_fit += 1\n",
        "\n",
        "\n",
        "    if over_fit >= 2:\n",
        "        print(\"early stop epoch \", epoch)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOzg0oQx6i1V"
      },
      "outputs": [],
      "source": [
        "class SAKTDatasetR(Dataset):\n",
        "    def __init__(self, group, n_skill, max_seq=MAX_SEQ): #HDKIM 100\n",
        "        super(SAKTDatasetR, self).__init__()\n",
        "        self.max_seq = max_seq\n",
        "        self.n_skill = n_skill\n",
        "        self.samples = group\n",
        "\n",
        "#         self.user_ids = [x for x in group.index]\n",
        "        self.user_ids = []\n",
        "        for user_id in group.index:\n",
        "            q, qa = group[user_id]\n",
        "            if len(q) < 2: #HDKIM 10\n",
        "                continue\n",
        "            self.user_ids.append(user_id)\n",
        "\n",
        "            #HDKIM Memory reduction\n",
        "            #if len(q)>self.max_seq:\n",
        "            #    group[user_id] = (q[-self.max_seq:],qa[-self.max_seq:])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.user_ids)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        user_id = self.user_ids[index]\n",
        "        q_, qa_ = self.samples[user_id]\n",
        "        seq_len = len(q_)\n",
        "\n",
        "        q = np.zeros(self.max_seq, dtype=int)\n",
        "        qa = np.zeros(self.max_seq, dtype=int)\n",
        "\n",
        "        if seq_len >= self.max_seq:\n",
        "            #HDKIM\n",
        "            if random.random()>0.1:\n",
        "                start = random.randint(0,(seq_len-self.max_seq))\n",
        "                end = start + self.max_seq\n",
        "                q[:] = q_[start:end]\n",
        "                qa[:] = qa_[start:end]\n",
        "            else:\n",
        "                #HDKIMHDKIM\n",
        "                q[:] = q_[-self.max_seq:]\n",
        "                qa[:] = qa_[-self.max_seq:]\n",
        "        else:\n",
        "            #HDKIM\n",
        "            if random.random()>0.1:\n",
        "                #HDKIMHDKIM\n",
        "                start = 0\n",
        "                end = random.randint(2,seq_len)\n",
        "                seq_len = end - start\n",
        "                q[-seq_len:] = q_[0:seq_len]\n",
        "                qa[-seq_len:] = qa_[0:seq_len]\n",
        "            else:\n",
        "                #HDKIMHDKIM\n",
        "                q[-seq_len:] = q_\n",
        "                qa[-seq_len:] = qa_\n",
        "\n",
        "\n",
        "        target_id = q[1:]\n",
        "        label = qa[1:]\n",
        "\n",
        "        x = np.zeros(self.max_seq-1, dtype=int)\n",
        "        x = q[:-1].copy()\n",
        "        x += (qa[:-1] == 1) * self.n_skill\n",
        "\n",
        "        return x, target_id, label"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train2, val2 = train_test_split(group, test_size=0.2)\n",
        "\n",
        "train_dataset2 = SAKTDatasetR(train2, n_skill)\n",
        "train_dataloader2 = DataLoader(train_dataset2, batch_size=64, shuffle=True, num_workers=8)\n",
        "del train\n",
        "\n",
        "val_dataset2 = SAKTDatasetR(val2, n_skill)\n",
        "val_dataloader2 = DataLoader(val_dataset2, batch_size=64, shuffle=True, num_workers=8)\n",
        "del val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivm_hy7vC4Jh",
        "outputId": "3caf4f82-29ee-4c35-aa55-2e78c82e0c5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# device = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "model2 = SAKTModel(n_skill, embed_dim=128)\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.99, weight_decay=0.005)\n",
        "optimizer = torch.optim.Adam(model2.parameters(), lr=1e-3)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model2.to(device)\n",
        "criterion.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6oe3SZWE3m1",
        "outputId": "93795c25-7cf8-4b05-dccd-142bcad958dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BCEWithLogitsLoss()"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "\n",
        "over_fit = 0\n",
        "last_auc = 0\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_acc, train_auc = train_epoch(model2, train_dataloader2, optimizer, criterion, device)\n",
        "    print(\"epoch - {} train_loss - {:.2f} acc - {:.3f} auc - {:.3f}\".format(epoch, train_loss, train_acc, train_auc))\n",
        "\n",
        "    val_loss, avl_acc, val_auc = val_epoch(model2, val_dataloader2, criterion, device)\n",
        "    print(\"epoch - {} val_loss - {:.2f} acc - {:.3f} auc - {:.3f}\".format(epoch, val_loss, avl_acc, val_auc))\n",
        "\n",
        "    if val_auc > last_auc:\n",
        "        last_auc = val_auc\n",
        "        over_fit = 0\n",
        "    else:\n",
        "        over_fit += 1\n",
        "\n",
        "\n",
        "    if over_fit >= 2:\n",
        "        print(\"early stop epoch \", epoch)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnFSI7v9DQ20",
        "outputId": "dff0e255-3f12-44cb-f73f-23de7355e5f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/364 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.5265: 100%|██████████| 364/364 [00:07<00:00, 48.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 0 train_loss - 0.51 acc - 0.772 auc - 0.664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/91 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.5568: 100%|██████████| 91/91 [00:02<00:00, 33.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 0 val_loss - 0.49 acc - 0.782 auc - 0.716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/364 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.2780: 100%|██████████| 364/364 [00:07<00:00, 45.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 1 train_loss - 0.48 acc - 0.786 auc - 0.724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/91 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4264: 100%|██████████| 91/91 [00:01<00:00, 48.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 1 val_loss - 0.48 acc - 0.783 auc - 0.730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/364 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4308: 100%|██████████| 364/364 [00:09<00:00, 39.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 2 train_loss - 0.47 acc - 0.789 auc - 0.737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/91 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4195: 100%|██████████| 91/91 [00:01<00:00, 48.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 2 val_loss - 0.48 acc - 0.788 auc - 0.737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/364 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4027: 100%|██████████| 364/364 [00:08<00:00, 40.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 3 train_loss - 0.47 acc - 0.792 auc - 0.743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/91 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4599: 100%|██████████| 91/91 [00:01<00:00, 48.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 3 val_loss - 0.47 acc - 0.788 auc - 0.741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/364 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.3928: 100%|██████████| 364/364 [00:08<00:00, 41.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 4 train_loss - 0.47 acc - 0.791 auc - 0.745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/91 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4397: 100%|██████████| 91/91 [00:02<00:00, 40.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 4 val_loss - 0.47 acc - 0.791 auc - 0.743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/364 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4250: 100%|██████████| 364/364 [00:07<00:00, 47.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 5 train_loss - 0.47 acc - 0.793 auc - 0.747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/91 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4537: 100%|██████████| 91/91 [00:02<00:00, 36.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 5 val_loss - 0.47 acc - 0.789 auc - 0.743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/364 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4923: 100%|██████████| 364/364 [00:08<00:00, 43.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 6 train_loss - 0.46 acc - 0.794 auc - 0.749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/91 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4324: 100%|██████████| 91/91 [00:01<00:00, 48.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 6 val_loss - 0.47 acc - 0.790 auc - 0.745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/364 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.3499: 100%|██████████| 364/364 [00:09<00:00, 37.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 7 train_loss - 0.46 acc - 0.794 auc - 0.750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/91 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.5159: 100%|██████████| 91/91 [00:01<00:00, 47.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 7 val_loss - 0.47 acc - 0.791 auc - 0.746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/364 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4321: 100%|██████████| 364/364 [00:10<00:00, 35.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 8 train_loss - 0.46 acc - 0.796 auc - 0.752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/91 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4060: 100%|██████████| 91/91 [00:01<00:00, 48.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 8 val_loss - 0.47 acc - 0.792 auc - 0.748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/364 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4430: 100%|██████████| 364/364 [00:08<00:00, 44.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 9 train_loss - 0.46 acc - 0.796 auc - 0.753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/91 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4976: 100%|██████████| 91/91 [00:02<00:00, 40.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 9 val_loss - 0.47 acc - 0.791 auc - 0.746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/364 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4863: 100%|██████████| 364/364 [00:07<00:00, 46.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 10 train_loss - 0.46 acc - 0.796 auc - 0.755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/91 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4741: 100%|██████████| 91/91 [00:02<00:00, 33.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 10 val_loss - 0.47 acc - 0.793 auc - 0.745\n",
            "early stop epoch  10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df = train_df.copy()\n",
        "df[\"memb_no\"] = df[\"memb_no\"].astype(\"str\")\n",
        "df[\"unit\"] = df[\"chapter_nm5\"].astype(\"str\")\n",
        "df[\"correct\"] = df[\"ox_yn\"].apply(lambda x: 1 if x == \"O\" else 0)"
      ],
      "metadata": {
        "id": "giySOV_sEaUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"unit\"] = df[\"unit\"].apply(lambda x: x.split(\".\")[-1].strip()).apply(lambda x: re.sub('\\(\\s*\\d+\\s*\\)', '', x).strip())\n",
        "df.unit.nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF_9thG7Flev",
        "outputId": "f59ed03d-1a62-48ac-bc22-2a79590c890d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9985"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "u_list = np.unique(df[\"memb_no\"].values)\n",
        "q_list = df.sort_values(by=[\"subject_cd\", \"chapter_cd\"])['unit'].unique()\n",
        "\n",
        "u2idx = {u: idx for idx, u in enumerate(u_list)}\n",
        "q2idx = {q: idx for idx, q in enumerate(q_list)}"
      ],
      "metadata": {
        "id": "6QknGjP_FocG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['content_id'] = df['unit'].replace(q2idx)"
      ],
      "metadata": {
        "id": "3DSOFW9NF_wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group = df[['memb_no', 'content_id', 'correct']].groupby('memb_no').apply(lambda r: (\n",
        "            r['content_id'].values,\n",
        "            r['correct'].values))"
      ],
      "metadata": {
        "id": "iRkfiyTBGEar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group"
      ],
      "metadata": {
        "id": "cFge7lahGIPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_skill = len(q2idx)\n",
        "n_skill"
      ],
      "metadata": {
        "id": "RPtGrZUWGNQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, val = train_test_split(group, test_size=0.2)\n",
        "\n",
        "train_dataset = SAKTDataset(train, n_skill)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=8)\n",
        "del train\n",
        "\n",
        "val_dataset = SAKTDataset(val, n_skill)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=True, num_workers=8)\n",
        "del val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BRVzgRHGXZD",
        "outputId": "b832f1f3-492b-4cc8-be74-99f73befed9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# device = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "model3 = SAKTModel(n_skill, embed_dim=128)\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.99, weight_decay=0.005)\n",
        "optimizer = torch.optim.Adam(model3.parameters(), lr=1e-3)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model3.to(device)\n",
        "criterion.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8W9eaJJYGcWh",
        "outputId": "a9f9753e-dd7c-4bc6-e12d-4b864f8ec720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BCEWithLogitsLoss()"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "\n",
        "over_fit = 0\n",
        "last_auc = 0\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_acc, train_auc = train_epoch(model3, train_dataloader, optimizer, criterion, device)\n",
        "    print(\"epoch - {} train_loss - {:.2f} acc - {:.3f} auc - {:.3f}\".format(epoch, train_loss, train_acc, train_auc))\n",
        "\n",
        "    val_loss, avl_acc, val_auc = val_epoch(model3, val_dataloader, criterion, device)\n",
        "    print(\"epoch - {} val_loss - {:.2f} acc - {:.3f} auc - {:.3f}\".format(epoch, val_loss, avl_acc, val_auc))\n",
        "\n",
        "    if val_auc > last_auc:\n",
        "        last_auc = val_auc\n",
        "        over_fit = 0\n",
        "    else:\n",
        "        over_fit += 1\n",
        "\n",
        "\n",
        "    if over_fit >= 2:\n",
        "        print(\"early stop epoch \", epoch)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo5O4oQIGpzr",
        "outputId": "226828d6-773e-4076-8e92-d8fca915ba2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss - 0.4695: 100%|██████████| 361/361 [00:10<00:00, 35.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 0 train_loss - 0.52 acc - 0.761 auc - 0.664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/91 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.6125: 100%|██████████| 91/91 [00:01<00:00, 66.15it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 0 val_loss - 0.49 acc - 0.772 auc - 0.739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/361 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4810: 100%|██████████| 361/361 [00:07<00:00, 51.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 1 train_loss - 0.46 acc - 0.788 auc - 0.771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/91 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4315: 100%|██████████| 91/91 [00:01<00:00, 64.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 1 val_loss - 0.47 acc - 0.784 auc - 0.776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/361 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4642: 100%|██████████| 361/361 [00:06<00:00, 56.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 2 train_loss - 0.44 acc - 0.798 auc - 0.797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/91 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.3959: 100%|██████████| 91/91 [00:02<00:00, 40.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 2 val_loss - 0.46 acc - 0.788 auc - 0.785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/361 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4225: 100%|██████████| 361/361 [00:07<00:00, 47.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 3 train_loss - 0.43 acc - 0.804 auc - 0.809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/91 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4333: 100%|██████████| 91/91 [00:01<00:00, 61.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 3 val_loss - 0.46 acc - 0.790 auc - 0.787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/361 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4382: 100%|██████████| 361/361 [00:08<00:00, 41.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 4 train_loss - 0.42 acc - 0.808 auc - 0.818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/91 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.5107: 100%|██████████| 91/91 [00:01<00:00, 62.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 4 val_loss - 0.46 acc - 0.789 auc - 0.787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/361 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4193: 100%|██████████| 361/361 [00:06<00:00, 53.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 5 train_loss - 0.42 acc - 0.812 auc - 0.827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/91 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4781: 100%|██████████| 91/91 [00:01<00:00, 47.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 5 val_loss - 0.46 acc - 0.789 auc - 0.786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/361 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4138: 100%|██████████| 361/361 [00:06<00:00, 56.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 6 train_loss - 0.41 acc - 0.816 auc - 0.834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/91 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.5549: 100%|██████████| 91/91 [00:01<00:00, 64.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 6 val_loss - 0.47 acc - 0.786 auc - 0.784\n",
            "early stop epoch  6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train5, val5 = train_test_split(group, test_size=0.2)\n",
        "\n",
        "train_dataset5 = SAKTDatasetR(train5, n_skill)\n",
        "train_dataloader5 = DataLoader(train_dataset5, batch_size=64, shuffle=True, num_workers=8)\n",
        "del train5\n",
        "\n",
        "val_dataset5 = SAKTDatasetR(val5, n_skill)\n",
        "val_dataloader5 = DataLoader(val_dataset5, batch_size=64, shuffle=True, num_workers=8)\n",
        "del val5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiBiwgW2Z6N9",
        "outputId": "fa3efc6a-8044-4050-9329-c0d5e5772776"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# device = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "model5 = SAKTModel(n_skill, embed_dim=128)\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.99, weight_decay=0.005)\n",
        "optimizer = torch.optim.Adam(model5.parameters(), lr=1e-3)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model5.to(device)\n",
        "criterion.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ3XqMDraoD2",
        "outputId": "b0c3c21a-ada3-49fc-87a7-bad57ffd996b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BCEWithLogitsLoss()"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "\n",
        "over_fit = 0\n",
        "last_auc = 0\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_acc, train_auc = train_epoch(model5, train_dataloader, optimizer, criterion, device)\n",
        "    print(\"epoch - {} train_loss - {:.2f} acc - {:.3f} auc - {:.5f}\".format(epoch, train_loss, train_acc, train_auc))\n",
        "\n",
        "    val_loss, avl_acc, val_auc = val_epoch(model5, val_dataloader, criterion, device)\n",
        "    print(\"epoch - {} val_loss - {:.2f} acc - {:.3f} auc - {:.5f}\".format(epoch, val_loss, avl_acc, val_auc))\n",
        "\n",
        "    if val_auc > last_auc:\n",
        "        last_auc = val_auc\n",
        "        over_fit = 0\n",
        "    else:\n",
        "        over_fit += 1\n",
        "\n",
        "\n",
        "    if over_fit >= 2:\n",
        "        print(\"early stop epoch \", epoch)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6piAhnXuaydr",
        "outputId": "af523d00-dbef-4182-bb4c-58334b56bb5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/361 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4787: 100%|██████████| 361/361 [00:07<00:00, 48.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 0 train_loss - 0.52 acc - 0.760 auc - 0.66070\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/91 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4803: 100%|██████████| 91/91 [00:01<00:00, 64.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 0 val_loss - 0.50 acc - 0.771 auc - 0.73624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/361 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4631: 100%|██████████| 361/361 [00:07<00:00, 47.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 1 train_loss - 0.46 acc - 0.787 auc - 0.76976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/91 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.5366: 100%|██████████| 91/91 [00:01<00:00, 66.54it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 1 val_loss - 0.47 acc - 0.785 auc - 0.77549\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/361 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4601: 100%|██████████| 361/361 [00:06<00:00, 56.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 2 train_loss - 0.44 acc - 0.798 auc - 0.79677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/91 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4838: 100%|██████████| 91/91 [00:02<00:00, 42.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 2 val_loss - 0.46 acc - 0.789 auc - 0.78465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/361 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4310: 100%|██████████| 361/361 [00:06<00:00, 51.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 3 train_loss - 0.43 acc - 0.804 auc - 0.80885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/91 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4078: 100%|██████████| 91/91 [00:01<00:00, 66.32it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 3 val_loss - 0.46 acc - 0.789 auc - 0.78663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/361 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4518: 100%|██████████| 361/361 [00:07<00:00, 47.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 4 train_loss - 0.43 acc - 0.808 auc - 0.81793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/91 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4435: 100%|██████████| 91/91 [00:02<00:00, 40.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 4 val_loss - 0.46 acc - 0.790 auc - 0.78751\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/361 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4301: 100%|██████████| 361/361 [00:07<00:00, 50.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 5 train_loss - 0.42 acc - 0.812 auc - 0.82611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/91 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4224: 100%|██████████| 91/91 [00:01<00:00, 46.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 5 val_loss - 0.46 acc - 0.786 auc - 0.78543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/361 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4489: 100%|██████████| 361/361 [00:06<00:00, 55.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 6 train_loss - 0.41 acc - 0.816 auc - 0.83396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/91 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "loss - 0.4692: 100%|██████████| 91/91 [00:01<00:00, 64.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch - 6 val_loss - 0.47 acc - 0.788 auc - 0.78372\n",
            "early stop epoch  6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/group_nm5_with_diff.pkl', 'rb') as f:\n",
        "    group = pickle.load(f)"
      ],
      "metadata": {
        "id": "dUdfYboLa5jI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SAKTDataset(Dataset):\n",
        "    def __init__(self, group, n_skill, max_seq=100):\n",
        "        super(SAKTDataset, self).__init__()\n",
        "        self.max_seq = max_seq\n",
        "        self.n_skill = n_skill\n",
        "        self.samples = group\n",
        "\n",
        "        self.user_ids = []\n",
        "        self.diff_levels = []  # 난이도 피처(diff_level)를 저장할 리스트 추가\n",
        "        for user_id in group.index:\n",
        "            q, qa, diff_level = group[user_id]\n",
        "\n",
        "            if len(q) < 10:\n",
        "                continue\n",
        "            self.user_ids.append(user_id)\n",
        "            self.diff_levels.append(diff_level)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.user_ids)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        user_id = self.user_ids[index]\n",
        "        q_, qa_, diff_level = self.samples[user_id]\n",
        "\n",
        "        seq_len = len(q_)\n",
        "\n",
        "        q = np.zeros(self.max_seq, dtype=int)\n",
        "        qa = np.zeros(self.max_seq, dtype=int)\n",
        "        if seq_len >= self.max_seq:\n",
        "            q[:self.max_seq] = q_[-self.max_seq:]\n",
        "            qa[:self.max_seq] = qa_[-self.max_seq:]\n",
        "        else:\n",
        "            q[self.max_seq-seq_len:] = q_\n",
        "            qa[self.max_seq-seq_len:] = qa_\n",
        "\n",
        "\n",
        "        target_id = q[1:]\n",
        "        label = qa[1:]\n",
        "\n",
        "        x = np.zeros(self.max_seq-1, dtype=int)\n",
        "        x = q[:-1].copy()\n",
        "        x += (qa[:-1] == 1) * self.n_skill\n",
        "\n",
        "        diff_level = np.array(diff_level[:-1], dtype=int)  # 마지막 시퀀스 제외 (예측 대상이 아님)\n",
        "\n",
        "        x_with_diff = np.concatenate([x, diff_level], axis=0)  # x와 난이도 피처를 결합\n",
        "\n",
        "        return x_with_diff, target_id, label\n",
        "\n"
      ],
      "metadata": {
        "id": "Mo7DsCNsGSoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "class SAKTDataset(nn.Module):\n",
        "    def __init__(self, group, n_skill, max_seq=100):\n",
        "        super(SAKTDataset, self).__init__()\n",
        "        self.max_seq = max_seq\n",
        "        self.n_skill = n_skill\n",
        "        self.samples = group\n",
        "\n",
        "        self.user_ids = []\n",
        "        self.diff_levels = []\n",
        "        for user_id in group.index:\n",
        "            q, qa, diff_level = group[user_id]\n",
        "\n",
        "            if len(q) < 10:\n",
        "                continue\n",
        "\n",
        "            self.user_ids.append(user_id)\n",
        "            self.diff_levels.append(diff_level)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.user_ids)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        user_id = self.user_ids[index]\n",
        "        q_, qa_, diff_level = self.samples[user_id]\n",
        "\n",
        "        seq_len = len(q_)\n",
        "\n",
        "        q = np.zeros(self.max_seq, dtype=int)\n",
        "        qa = np.zeros(self.max_seq, dtype=int)\n",
        "        if seq_len >= self.max_seq:\n",
        "            q[:self.max_seq] = q_[-self.max_seq:]\n",
        "            qa[:self.max_seq] = qa_[-self.max_seq:]\n",
        "        else:\n",
        "            q[self.max_seq-seq_len:] = q_\n",
        "            qa[self.max_seq-seq_len:] = qa_\n",
        "\n",
        "\n",
        "        target_id = q[1:]\n",
        "        label = qa[1:]\n",
        "\n",
        "        x = np.zeros(self.max_seq-1, dtype=int)\n",
        "        x = q[:-1].copy()\n",
        "        x += (qa[:-1] == 1) * self.n_skill\n",
        "\n",
        "        diff_level = np.array(diff_level[:-1], dtype=int)  # 마지막 시퀀스 제외 (예측 대상이 아님)\n",
        "\n",
        "        # x와 diff_level의 크기를 맞추기 위해 패딩\n",
        "        x = np.pad(x, (0, self.max_seq-1-len(x)), mode='constant')\n",
        "        diff_level = np.pad(diff_level, (0, self.max_seq-1-len(diff_level)), mode='constant')\n",
        "\n",
        "        x_with_diff = np.concatenate([x, diff_level], axis=0)  # x와 난이도 피처를 결합\n",
        "\n",
        "        return x_with_diff, target_id, label\n",
        "\n",
        "\n",
        "class FFN(nn.Module):\n",
        "    def __init__(self, state_size=200):\n",
        "        super(FFN, self).__init__()\n",
        "        self.state_size = state_size\n",
        "\n",
        "        self.lr1 = nn.Linear(state_size, state_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.lr2 = nn.Linear(state_size, state_size)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lr1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.lr2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def future_mask(seq_length):\n",
        "    future_mask = torch.triu(torch.ones((seq_length, seq_length), dtype=torch.bool), diagonal=1)\n",
        "    return future_mask\n",
        "\n",
        "\n",
        "class SAKTModel(nn.Module):\n",
        "    def __init__(self, n_skill, max_seq=100, embed_dim=128):\n",
        "        super(SAKTModel, self).__init__()\n",
        "        self.n_skill = n_skill\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(2*n_skill+1, embed_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_seq-1, embed_dim)\n",
        "        self.e_embedding = nn.Embedding(n_skill+1, embed_dim)\n",
        "\n",
        "        self.multi_att = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=8, dropout=0.2)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.layer_normal = nn.LayerNorm(embed_dim)\n",
        "\n",
        "        self.ffn = FFN(embed_dim)\n",
        "        self.pred = nn.Linear(embed_dim + 1, 1)  # 난이도 피처를 고려하여 선형 레이어 수정\n",
        "\n",
        "    def forward(self, x, question_ids):\n",
        "        device = x.device\n",
        "        x = self.embedding(x)\n",
        "        pos_id = torch.arange(x.size(1)).unsqueeze(0).to(device)\n",
        "        pos_x = self.pos_embedding(pos_id)\n",
        "        pos_x = pos_x.expand(x.size(0), -1, -1)\n",
        "\n",
        "        x = x + pos_x\n",
        "\n",
        "        e = self.e_embedding(question_ids)\n",
        "\n",
        "        x = x.permute(1, 0, 2)  # x: [bs, s_len, embed] => [s_len, bs, embed]\n",
        "        e = e.permute(1, 0, 2)\n",
        "\n",
        "        att_mask = torch.triu(torch.ones((x.size(1), x.size(1)), dtype=torch.bool), diagonal=1).to(device)\n",
        "\n",
        "        att_output, att_weight = self.multi_att(e, x, x, attn_mask=att_mask)\n",
        "        att_output = self.layer_normal(att_output + e)\n",
        "        att_output = att_output.permute(1, 0, 2)  # att_output: [s_len, bs, embed] => [bs, s_len, embed]\n",
        "\n",
        "        x = self.ffn(att_output)\n",
        "        x = self.layer_normal(x + att_output)\n",
        "\n",
        "        # 난이도 피처를 x와 결합하여 모델의 입력에 추가\n",
        "        x_with_diff = torch.cat([x, diff_level.unsqueeze(0).expand(x.size(0), -1).to(x.device)], dim=0)\n",
        "\n",
        "        x_with_diff = self.dropout(x_with_diff)\n",
        "\n",
        "        x = self.pred(x_with_diff)\n",
        "\n",
        "        return x.squeeze(-1), att_weight\n"
      ],
      "metadata": {
        "id": "lFavznUfR5Pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, val = train_test_split(group, test_size=0.2)\n",
        "\n",
        "train_dataset = SAKTDataset(train,9, n_skill)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=8)\n",
        "del train\n",
        "\n",
        "val_dataset = SAKTDataset(val, 9,n_skill)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=True, num_workers=8)\n",
        "del val"
      ],
      "metadata": {
        "id": "ug0yNzC7GxFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "\n",
        "over_fit = 0\n",
        "last_auc = 0\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_acc, train_auc = train_epoch(model, train_dataloader, optimizer, criterion, device)\n",
        "    print(\"epoch - {} train_loss - {:.2f} acc - {:.3f} auc - {:.5f}\".format(epoch, train_loss, train_acc, train_auc))\n",
        "\n",
        "    val_loss, avl_acc, val_auc = val_epoch(model, val_dataloader, criterion, device)\n",
        "    print(\"epoch - {} val_loss - {:.2f} acc - {:.3f} auc - {:.5f}\".format(epoch, val_loss, avl_acc, val_auc))\n",
        "\n",
        "    if val_auc > last_auc:\n",
        "        last_auc = val_auc\n",
        "        over_fit = 0\n",
        "    else:\n",
        "        over_fit += 1\n",
        "\n",
        "\n",
        "    if over_fit >= 2:\n",
        "        print(\"early stop epoch \", epoch)\n",
        "        break"
      ],
      "metadata": {
        "id": "lsXHyQzrHSlQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}